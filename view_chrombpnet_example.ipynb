{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will instead use the examples in the full chrombpnet repo. This is saved in chrombpnet test\n",
    "#it has 3 replicates of the bam files, and uses a separate reference genome, but we can compare it to our old reference genome\n",
    "# samtools merge -f merged_unsorted.bam rep1.bam  rep2.bam  rep3.bam\n",
    "# samtools sort -@4 merged_unsorted.bam -o merged.bam\n",
    "# samtools index merged.bam\n",
    "\n",
    "\n",
    "#chrombpnet prep splits -c hg38.chrom.subset.sizes -tcr chr11 chr12 -vcr chr8 chr10 -op splits/fold_0\n",
    "#this command isn't included, so we just manually made this instead\n",
    "\n",
    "#also one part where we have to implment it...\n",
    "#chrombpnet prep nonpeaks -g ~/chrombpnet_tutorial/data/downloads/hg38.fa -p ~/chrombpnet_tutorial/data/peaks_no_blacklist.bed -c  ~/chrombpnet_tutorial/data/downloads/hg38.chrom.sizes -fl ~/chrombpnet_tutorial/data/splits/fold_0.json -br ~/chrombpnet_tutorial/data/downloads/blacklist.bed.gz -o ~/chrombpnet_tutorial/data/output\n",
    "#\targs = parsers.read_parser()\n",
    "\n",
    "#made a simple test to see what args is\n",
    "\n",
    "# python utils/test_args.py prep nonpeaks -g hg38.fa -p peaks_no_blacklist.bed -c  hg38.chrom.sizes -fl fold_0.json -br blacklist.bed.gz -o /data/output\n",
    "# Namespace(cmd='prep', cmd_prep='nonpeaks', genome='hg38.fa', output_prefix='/data/output', peaks='peaks_no_blacklist.bed', chrom_sizes='hg38.chrom.sizes', chr_fold_path='fold_0.json', inputlen=2114, stride=1000, neg_to_pos_ratio_train=2, blacklist_regions='blacklist.bed.gz', seed=1234)\n",
    "#can look at the parser to see what the commands like -g are, -g is genome, -p is peaks, etc.\n",
    "#it's the section right after general training args!\n",
    "#but we don't actually really need it, can just copy the functions over!\n",
    "# so we got all of it, let's see what happens if we call that?\n",
    "\n",
    "# python utils/prep_nonpeaks.py prep nonpeaks -g hg38.fa -p peaks_no_blacklist.bed -c  hg38.chrom.sizes -fl splits/fold_0.json -br blacklist.bed.gz -o output\n",
    "\n",
    "#this has an issue with the args.input\n",
    "#it was actually an issue with the data, we somehow downloaded the overlap file incorrectly, we'll make this process much better later on and use the built in pipelines, but for now,need to understand what it's doing! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can view the final files, we have this merged and index bam file, let's view this\n",
    "#he actually also has an easy way to get the gc content, which is pretty easy to use\n",
    "#bpnet negatives -i <peaks>.bed -f <fasta>.fa -b <bigwig>.bw -o matched_loci.bed -l 0.02 -w 2114 -v\n",
    "#wait, we don't have a bigwig file??\n",
    "\n",
    "#but we have the negatives, so it doesn't matter\n",
    "#now let's create the json for training, we need\n",
    "\n",
    "#we need to create the bigwig file as well\n",
    "#bedtools genomecov -5 -bg -g hg38.chrom.sizes -ibam merged.bam | sort -k1,1 -k2,2n > data.bedGraph\n",
    "# ./bedGraphToBigWig data.bedGraph <your genome>.chrom.sizes data.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's do this again with actual chrombpnet package\n",
    "# first mamba install all the things they say and tensorflow-gpu=2.8.0\n",
    "# chrombpnet bias pipeline \\\n",
    "#         -ibam merged.bam \\\n",
    "#         -d \"ATAC\" \\\n",
    "#         -g hg38.fa \\\n",
    "#         -c hg38.chrom.sizes \\\n",
    "#         -p peaks_no_blacklist.bed \\\n",
    "#         -n output_negatives.bed \\\n",
    "#         -fl splits/fold_0.json \\\n",
    "#         -b 0.5 \\\n",
    "#         -o bias_model/ \\\n",
    "#         -fp k562 \\\n",
    "\n",
    "#that's hwo we'll train this bias model, then we can do the full model\n",
    "\n",
    "#then we train the actual model\n",
    "\n",
    "# chrombpnet pipeline \\\n",
    "#         -ibam merged.bam \\\n",
    "#         -d \"ATAC\" \\\n",
    "#         -g hg38.fa \\\n",
    "#         -c hg38.chrom.sizes \\\n",
    "#         -p peaks_no_blacklist.bed \\\n",
    "#         -n output_negatives.bed \\\n",
    "#         -fl splits/fold_0.json \\\n",
    "#         -b bias_model/models/k562_bias.h5 \\\n",
    "#         -o chrombpnet_model/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
