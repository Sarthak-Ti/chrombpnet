{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple script to test loading the bias model into pytorch\n",
    "#we have some scripts stored in bpnet lite\n",
    "import sys\n",
    "sys.path.append('/data/leslie/sarthak/chrombpnet')\n",
    "from bpnetlite.bpnet import BPNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try loading the model using the model method\n",
    "model = BPNet.from_chrombpnet('/data/leslie/sarthak/data/chrombpnet_test/bias_model/models/k562_bias.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/core/formatters.py:711\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    704\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    705\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    707\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    708\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    709\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    710\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 711\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:411\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    410\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 411\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:779\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2526\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2524\u001b[0m child_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 2526\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m _addindent(mod_str, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     child_lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mod_str)\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2520\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;66;03m# We treat the extra repr like the sub-module, one item per line\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m     extra_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2520\u001b[0m     extra_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# empty string will be split into list ['']\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_repr:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/conv.py:157\u001b[0m, in \u001b[0;36m_ConvNd.extra_repr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextra_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    155\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{in_channels}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{out_channels}\u001b[39;00m\u001b[38;5;124m, kernel_size=\u001b[39m\u001b[38;5;132;01m{kernel_size}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, stride=\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m0\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    158\u001b[0m         s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding=\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bpnetlite.bpnet.BPNet'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m) \u001b[38;5;66;03m#this does work\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Print the __dict__ attribute of the model\u001b[39;00m\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2520\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;66;03m# We treat the extra repr like the sub-module, one item per line\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m     extra_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2520\u001b[0m     extra_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# empty string will be split into list ['']\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_repr:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/conv.py:157\u001b[0m, in \u001b[0;36m_ConvNd.extra_repr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextra_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    155\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{in_channels}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{out_channels}\u001b[39;00m\u001b[38;5;124m, kernel_size=\u001b[39m\u001b[38;5;132;01m{kernel_size}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, stride=\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m0\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    158\u001b[0m         s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding=\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "print(model.__class__) #this does work\n",
    "print(vars(model))  # Print the __dict__ attribute of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: True\n",
      "_parameters: OrderedDict()\n",
      "_buffers: OrderedDict()\n",
      "_non_persistent_buffers_set: set()\n",
      "_backward_pre_hooks: OrderedDict()\n",
      "_backward_hooks: OrderedDict()\n",
      "_is_full_backward_hook: None\n",
      "_forward_hooks: OrderedDict()\n",
      "_forward_hooks_with_kwargs: OrderedDict()\n",
      "_forward_hooks_always_called: OrderedDict()\n",
      "_forward_pre_hooks: OrderedDict()\n",
      "_forward_pre_hooks_with_kwargs: OrderedDict()\n",
      "_state_dict_hooks: OrderedDict()\n",
      "_state_dict_pre_hooks: OrderedDict()\n",
      "_load_state_dict_pre_hooks: OrderedDict()\n",
      "_load_state_dict_post_hooks: OrderedDict()\n",
      "Error printing _modules: object of type 'int' has no len()\n",
      "n_filters: 128\n",
      "n_layers: 4\n",
      "n_outputs: 1\n",
      "n_control_tracks: 0\n",
      "alpha: 1\n",
      "name: bpnet.128.4\n",
      "trimming: 557\n",
      "logger: <bpnetlite.logging.Logger object at 0x7f1396422570>\n"
     ]
    }
   ],
   "source": [
    "def inspect_attributes(obj):\n",
    "    for attr, value in obj.__dict__.items():\n",
    "        try:\n",
    "            print(f\"{attr}: {value}\")\n",
    "        except TypeError as e:\n",
    "            print(f\"Error printing {attr}: {e}\")\n",
    "\n",
    "inspect_attributes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 64, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "    (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "    (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "    (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "    (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-7): 8 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(66, 2, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=65, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's first load the model without any weights\n",
    "model = BPNet()\n",
    "model #ok this seems fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('iconv',\n",
       "              Conv1d(4, 64, kernel_size=(21,), stride=(1,), padding=(10,))),\n",
       "             ('irelu', ReLU()),\n",
       "             ('rconvs',\n",
       "              ModuleList(\n",
       "                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "                (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "                (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "                (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "                (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "                (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "                (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "                (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "              )),\n",
       "             ('rrelus',\n",
       "              ModuleList(\n",
       "                (0-7): 8 x ReLU()\n",
       "              )),\n",
       "             ('fconv',\n",
       "              Conv1d(66, 2, kernel_size=(75,), stride=(1,), padding=(37,))),\n",
       "             ('linear', Linear(in_features=65, out_features=1, bias=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['add', 'add_1', 'add_2', 'add_3', 'bpnet_1conv', 'bpnet_1crop', 'bpnet_1st_conv', 'bpnet_2conv', 'bpnet_2crop', 'bpnet_3conv', 'bpnet_3crop', 'bpnet_4conv', 'bpnet_4crop', 'gap', 'logcount_predictions', 'logits_profile_predictions', 'logits_profile_predictions_preflatten', 'prof_out_precrop', 'sequence', 'top_level_model_weights']>\n"
     ]
    }
   ],
   "source": [
    "#let's go through this step by step\n",
    "import torch\n",
    "import h5py\n",
    "filename = '/data/leslie/sarthak/data/chrombpnet_test/bias_model/models/k562_bias.h5'\n",
    "\n",
    "h5 = h5py.File(filename, \"r\")\n",
    "w = h5['model_weights']\n",
    "\n",
    "print(w.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(w.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_name: add\n",
      "add_1 1\n",
      "add_2 2\n",
      "add_3 3\n",
      "bpnet_1conv 1\n",
      "layer_name: bpnet_1crop\n",
      "layer_name: bpnet_1st_conv\n",
      "bpnet_2conv 2\n",
      "layer_name: bpnet_2crop\n",
      "bpnet_3conv 3\n",
      "layer_name: bpnet_3crop\n",
      "bpnet_4conv 4\n",
      "layer_name: bpnet_4crop\n",
      "layer_name: gap\n",
      "layer_name: logcount_predictions\n",
      "layer_name: logits_profile_predictions\n",
      "layer_name: logits_profile_predictions_preflatten\n",
      "layer_name: prof_out_precrop\n",
      "layer_name: sequence\n",
      "layer_name: top_level_model_weights\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "if 'bpnet_1conv' in w.keys():\n",
    "    prefix = \"\"\n",
    "else:\n",
    "    prefix = \"wo_bias_\"\n",
    "\n",
    "namer = lambda prefix, suffix: '{0}{1}/{0}{1}'.format(prefix, suffix)\n",
    "k, b = 'kernel:0', 'bias:0'\n",
    "\n",
    "n_layers = 0\n",
    "for layer_name in w.keys():\n",
    "    try:\n",
    "        idx = int(layer_name.split(\"_\")[-1].replace(\"conv\", \"\"))\n",
    "        print(layer_name, idx)\n",
    "        n_layers = max(n_layers, idx)\n",
    "    except:\n",
    "        print('layer_name:', layer_name) #ahh, several of them come here and there's some issue here...\n",
    "        pass\n",
    "print(n_layers) #does correctly find that there's 4 layers so this is not the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnet_1conv/bpnet_1conv\n",
      "128\n",
      "BPNet(\n",
      "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "  (irelu): ReLU()\n",
      "  (rconvs): ModuleList(\n",
      "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "  )\n",
      "  (rrelus): ModuleList(\n",
      "    (0-3): 4 x ReLU()\n",
      "  )\n",
      "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
      "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "name = namer(prefix, \"bpnet_1conv\")\n",
    "n_filters = w[name][k].shape[2]\n",
    "print(name)\n",
    "print(n_filters)\n",
    "\n",
    "model = BPNet(n_layers=n_layers, n_filters=n_filters, n_outputs=1,\n",
    "    n_control_tracks=0, trimming=(2114-1000)//2)\n",
    "print(model) #this loads just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_w = lambda x: torch.nn.Parameter(torch.tensor(\n",
    "    x[:]).permute(2, 1, 0))\n",
    "convert_b = lambda x: torch.nn.Parameter(torch.tensor(x[:]))\n",
    "\n",
    "iname = namer(prefix, 'bpnet_1st_conv')\n",
    "\n",
    "model.iconv.weight = convert_w(w[iname][k])\n",
    "model.iconv.bias = convert_b(w[iname][b])\n",
    "model.iconv.padding = (21 - 1) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/core/formatters.py:711\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    704\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    705\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    707\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    708\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    709\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    710\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 711\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:411\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    410\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 411\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:779\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2526\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2524\u001b[0m child_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 2526\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m _addindent(mod_str, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     child_lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mod_str)\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2520\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;66;03m# We treat the extra repr like the sub-module, one item per line\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m     extra_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2520\u001b[0m     extra_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# empty string will be split into list ['']\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_repr:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/conv.py:157\u001b[0m, in \u001b[0;36m_ConvNd.extra_repr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextra_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    155\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{in_channels}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{out_channels}\u001b[39;00m\u001b[38;5;124m, kernel_size=\u001b[39m\u001b[38;5;132;01m{kernel_size}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, stride=\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m0\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    158\u001b[0m         s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding=\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "model #ahh here it is we found the issue, let's investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n"
     ]
    }
   ],
   "source": [
    "model = BPNet(n_layers=n_layers, n_filters=n_filters, n_outputs=1,\n",
    "    n_control_tracks=0, trimming=(2114-1000)//2)\n",
    "print(model.iconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4, 21])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_w(w[iname][k]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "BPNet(\n",
      "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "  (irelu): ReLU()\n",
      "  (rconvs): ModuleList(\n",
      "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "  )\n",
      "  (rrelus): ModuleList(\n",
      "    (0-3): 4 x ReLU()\n",
      "  )\n",
      "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
      "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.iconv.weight = convert_w(w[iname][k])\n",
    "print(model.iconv)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "#that is also fine, is it th enext one?\n",
    "print(convert_b(w[iname][b]).shape)\n",
    "print(model.iconv.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPNet(\n",
      "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "  (irelu): ReLU()\n",
      "  (rconvs): ModuleList(\n",
      "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "  )\n",
      "  (rrelus): ModuleList(\n",
      "    (0-3): 4 x ReLU()\n",
      "  )\n",
      "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
      "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.iconv.bias = convert_b(w[iname][b])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#so it's this last thing?\n",
    "print(model.iconv.padding)\n",
    "print((21 - 1) // 2)\n",
    "\n",
    "#it's because it's a fuckign int instead of a tuple... wtf??\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, n_layers+1):\n",
    "    lname = namer(prefix, 'bpnet_{}conv'.format(i))\n",
    "\n",
    "    model.rconvs[i-1].weight = convert_w(w[lname][k])\n",
    "    model.rconvs[i-1].bias = convert_b(w[lname][b])\n",
    "\n",
    "prefix = prefix + \"bpnet_\" if prefix != \"\" else \"\"\n",
    "\n",
    "fname = namer(prefix, 'prof_out_precrop')\n",
    "model.fconv.weight = convert_w(w[fname][k])\n",
    "model.fconv.bias = convert_b(w[fname][b])\n",
    "model.fconv.padding = (75 - 1) // 2\n",
    "\n",
    "name = namer(prefix, \"logcount_predictions\")\n",
    "model.linear.weight = torch.nn.Parameter(torch.tensor(w[name][k][:].T))\n",
    "model.linear.bias = convert_b(w[name][b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/core/formatters.py:711\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    704\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    705\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    707\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    708\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    709\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    710\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 711\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:411\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    410\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 411\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/IPython/lib/pretty.py:779\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2526\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2524\u001b[0m child_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 2526\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m _addindent(mod_str, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     child_lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mod_str)\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/module.py:2520\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;66;03m# We treat the extra repr like the sub-module, one item per line\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m     extra_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2520\u001b[0m     extra_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# empty string will be split into list ['']\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_repr:\n",
      "File \u001b[0;32m/data/leslie/sarthak/environments/bpnet/lib/python3.12/site-packages/torch/nn/modules/conv.py:157\u001b[0m, in \u001b[0;36m_ConvNd.extra_repr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextra_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    155\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{in_channels}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{out_channels}\u001b[39;00m\u001b[38;5;124m, kernel_size=\u001b[39m\u001b[38;5;132;01m{kernel_size}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    156\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, stride=\u001b[39m\u001b[38;5;132;01m{stride}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m0\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    158\u001b[0m         s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding=\u001b[39m\u001b[38;5;132;01m{padding}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-3): 4 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there's probalby another similar error...\n",
    "model = BPNet(n_layers=n_layers, n_filters=n_filters, n_outputs=1,\n",
    "    n_control_tracks=0, trimming=(2114-1000)//2)\n",
    "\n",
    "for i in range(1, n_layers+1):\n",
    "    lname = namer(prefix, 'bpnet_{}conv'.format(i))\n",
    "\n",
    "    model.rconvs[i-1].weight = convert_w(w[lname][k])\n",
    "    model.rconvs[i-1].bias = convert_b(w[lname][b])\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-3): 4 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = namer(prefix, 'prof_out_precrop')\n",
    "model.fconv.weight = convert_w(w[fname][k])\n",
    "model.fconv.bias = convert_b(w[fname][b])\n",
    "# model.fconv.padding = (75 - 1) // 2 #bro it's this fucking int again\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = namer(prefix, \"logcount_predictions\")\n",
    "model.linear.weight = torch.nn.Parameter(torch.tensor(w[name][k][:].T))\n",
    "model.linear.bias = convert_b(w[name][b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-3): 4 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37,)\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(model.fconv.padding)\n",
    "print(74//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's fix it and run it with hyena again and just comment out those 2 line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 128, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-3): 4 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(128, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a simple script to test loading the bias model into pytorch\n",
    "#we have some scripts stored in bpnet lite\n",
    "import sys\n",
    "sys.path.append('/data/leslie/sarthak/chrombpnet')\n",
    "from bpnetlite.bpnet import BPNet\n",
    "\n",
    "#now let's try loading the model using the model method\n",
    "model = BPNet.from_chrombpnet('/data/leslie/sarthak/data/chrombpnet_test/bias_model/models/k562_bias.h5')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1, 1000])\n",
      "torch.Size([64, 1])\n",
      "(tensor([[[ 16.5500, -20.1725,  12.6976,  ...,  -2.3728,  11.5527,  -7.2329]],\n",
      "\n",
      "        [[ 13.6432,  -0.7343,  20.7340,  ...,   3.0503,  18.0686,  18.2985]],\n",
      "\n",
      "        [[ 10.6004,  -5.5268,  -2.5166,  ...,  26.0202,  10.9781,   1.2610]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 12.5137,   2.9826,  14.4564,  ...,  -3.8280,   5.0520,   7.3202]],\n",
      "\n",
      "        [[ -6.4231,  -5.2557,  13.0977,  ...,  22.6658,  18.4078,  -2.7688]],\n",
      "\n",
      "        [[ 25.8086,  -3.8405,  14.2526,  ...,  -7.3776,  22.0719,   4.5368]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[17.0681],\n",
      "        [16.6567],\n",
      "        [17.0603],\n",
      "        [16.4891],\n",
      "        [16.4478],\n",
      "        [16.5447],\n",
      "        [16.7957],\n",
      "        [16.7515],\n",
      "        [16.3491],\n",
      "        [16.7141],\n",
      "        [16.7493],\n",
      "        [16.7669],\n",
      "        [16.9877],\n",
      "        [16.2577],\n",
      "        [16.9937],\n",
      "        [16.1349],\n",
      "        [16.6623],\n",
      "        [16.8176],\n",
      "        [16.5313],\n",
      "        [16.6301],\n",
      "        [16.9759],\n",
      "        [16.4674],\n",
      "        [16.9006],\n",
      "        [17.1580],\n",
      "        [16.6371],\n",
      "        [16.4879],\n",
      "        [16.5593],\n",
      "        [16.4193],\n",
      "        [16.4062],\n",
      "        [16.6419],\n",
      "        [16.3884],\n",
      "        [16.8322],\n",
      "        [16.4545],\n",
      "        [17.0272],\n",
      "        [16.7435],\n",
      "        [16.7294],\n",
      "        [16.8181],\n",
      "        [16.6641],\n",
      "        [16.6363],\n",
      "        [16.9863],\n",
      "        [16.7132],\n",
      "        [16.5557],\n",
      "        [16.4059],\n",
      "        [16.3061],\n",
      "        [17.0743],\n",
      "        [17.0524],\n",
      "        [16.7875],\n",
      "        [16.8945],\n",
      "        [16.5815],\n",
      "        [16.6852],\n",
      "        [16.6389],\n",
      "        [16.8158],\n",
      "        [16.5511],\n",
      "        [16.7305],\n",
      "        [16.7303],\n",
      "        [16.1960],\n",
      "        [16.6221],\n",
      "        [16.7001],\n",
      "        [16.8114],\n",
      "        [16.9866],\n",
      "        [16.9045],\n",
      "        [16.7446],\n",
      "        [16.7593],\n",
      "        [16.8023]], grad_fn=<ViewBackward0>))\n"
     ]
    }
   ],
   "source": [
    "#and this works, just had to comment out those 2 lines lol!\n",
    "#let's make a random size input\n",
    "import torch\n",
    "data = torch.rand(64,4,2114)*10\n",
    "out = model(data)\n",
    "print(len(out))\n",
    "print(out[0].shape) #the profile\n",
    "print(out[1].shape) #the counts\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1, 3000])\n",
      "torch.Size([64, 1])\n",
      "(tensor([[[ 14.5144,  10.0297,   4.6547,  ...,  -5.2196,  15.5950,  16.0039]],\n",
      "\n",
      "        [[  6.9590,   6.0129,   0.6853,  ...,   8.6671,  -5.7772,  24.9934]],\n",
      "\n",
      "        [[  4.4261,  18.9802, -14.9654,  ...,   1.6526,   9.3276,  -7.7576]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  5.3253,  15.5626,   5.4877,  ...,  21.5688,   5.2422,   9.4834]],\n",
      "\n",
      "        [[ -9.1263,  17.5073,  22.9212,  ...,  15.4544,   8.4311,   3.6903]],\n",
      "\n",
      "        [[  9.9269,   5.3502,  -2.9786,  ...,   2.7305,  -2.3351,  17.0411]]],\n",
      "       grad_fn=<SliceBackward0>), tensor([[16.6574],\n",
      "        [16.8335],\n",
      "        [16.6536],\n",
      "        [16.6040],\n",
      "        [16.8681],\n",
      "        [16.6982],\n",
      "        [16.5354],\n",
      "        [16.6358],\n",
      "        [16.7911],\n",
      "        [16.4574],\n",
      "        [16.6465],\n",
      "        [16.6201],\n",
      "        [16.7730],\n",
      "        [16.4544],\n",
      "        [16.6272],\n",
      "        [16.4799],\n",
      "        [16.5811],\n",
      "        [16.8360],\n",
      "        [16.6037],\n",
      "        [16.5485],\n",
      "        [16.7343],\n",
      "        [16.8720],\n",
      "        [16.6530],\n",
      "        [16.3497],\n",
      "        [16.6147],\n",
      "        [16.6390],\n",
      "        [16.7799],\n",
      "        [16.9830],\n",
      "        [16.5390],\n",
      "        [16.7391],\n",
      "        [16.6005],\n",
      "        [16.6205],\n",
      "        [16.6904],\n",
      "        [16.6717],\n",
      "        [16.7978],\n",
      "        [16.6340],\n",
      "        [16.6006],\n",
      "        [16.4455],\n",
      "        [16.7427],\n",
      "        [16.7052],\n",
      "        [16.6782],\n",
      "        [16.6130],\n",
      "        [16.6388],\n",
      "        [16.6743],\n",
      "        [16.7054],\n",
      "        [16.7915],\n",
      "        [16.8895],\n",
      "        [16.5472],\n",
      "        [16.6552],\n",
      "        [16.9104],\n",
      "        [16.6608],\n",
      "        [16.6261],\n",
      "        [16.7355],\n",
      "        [16.6136],\n",
      "        [16.7087],\n",
      "        [16.4630],\n",
      "        [16.6507],\n",
      "        [16.6122],\n",
      "        [16.6674],\n",
      "        [16.7097],\n",
      "        [16.6750],\n",
      "        [16.7331],\n",
      "        [16.5033],\n",
      "        [16.7360]], grad_fn=<ViewBackward0>))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.rand(64,4,4114)*10\n",
    "out = model(data)\n",
    "print(len(out))\n",
    "print(out[0].shape) #the profile\n",
    "print(out[1].shape) #the counts\n",
    "print(out) #works as long as it is able to crop out a certian amount! In this case crops out a total of 2114, but we can likely adjust this somewhere in the model to be 800!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 2114])\n",
      "2\n",
      "torch.Size([64, 1, 1000])\n",
      "torch.Size([64, 1])\n",
      "(tensor([[[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]],\n",
      "\n",
      "        [[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]],\n",
      "\n",
      "        [[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]],\n",
      "\n",
      "        [[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]],\n",
      "\n",
      "        [[ -965.9982,  -967.7639,  -969.5287,  ..., -2726.4048,\n",
      "          -2728.1697, -2729.9338]]], grad_fn=<SliceBackward0>), tensor([[3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576],\n",
      "        [3082.0576]], grad_fn=<ViewBackward0>))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = torch.tensor(range(2114), dtype=torch.float32).view(1,1,2114)\n",
    "#now make it 64 x 4 x 2114\n",
    "data = data.repeat(64,4,1)\n",
    "print(data.shape)\n",
    "out = model(data)\n",
    "print(len(out))\n",
    "print(out[0].shape) #the profile\n",
    "print(out[1].shape) #the counts\n",
    "print(out)\n",
    "#now it's a big question of if we can see similar results for the same input in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing tensorflow model and seeing how similar the input is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cmd='pipeline', genome='hg38.fa', chrom_sizes='hg38.chrom.sizes', input_bam_file='merged.bam', input_fragment_file=None, input_tagalign_file=None, output_dir='chrombpnet_model/', data_type='ATAC', peaks='peaks_no_blacklist.bed', nonpeaks='output_negatives.bed', chr_fold_path='splits/fold_0.json', outlier_threshold=0.9999, ATAC_ref_path=None, DNASE_ref_path=None, num_samples=10000, inputlen=2114, outputlen=1000, seed=1234, epochs=50, early_stop=5, learning_rate=0.001, trackables=['logcount_predictions_loss', 'loss', 'logits_profile_predictions_loss', 'val_logcount_predictions_loss', 'val_loss', 'val_logits_profile_predictions_loss'], architecture_from_file=None, file_prefix=None, html_prefix='./', bsort=False, tmpdir=None, no_st=False, skip_preprocessing=False, save_data=False, bias_model_path='bias_model/models/k562_bias.h5', negative_sampling_ratio=0.1, filters=512, n_dilation_layers=8, max_jitter=500, batch_size=64)\n",
      "{'counts_loss_weight': '76.2', 'filters': '512', 'n_dil_layers': '8', 'bias_model_path': 'chrombpnet_model/models/bias_model_scaled.h5', 'inputlen': '2114', 'outputlen': '1000', 'max_jitter': '500', 'chr_fold_path': 'splits/fold_0.json', 'negative_sampling_ratio': '0.1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 15:04:51.278776: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 15:04:57.437697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9459 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2024-06-11 15:04:57.447099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9459 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:5e:00.0, compute capability: 7.5\n",
      "2024-06-11 15:04:57.449117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9459 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:d8:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got the model\n"
     ]
    }
   ],
   "source": [
    "#we use the chrombpnet environment and get the model here\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append('/data/leslie/sarthak/chrombpnet/chrombpnet/')\n",
    "from test_args import main\n",
    "\n",
    "sys.argv = [\n",
    "    'test_args.py', 'pipeline',\n",
    "    '-ibam', 'merged.bam',\n",
    "    '-d', 'ATAC',\n",
    "    '-g', 'hg38.fa',\n",
    "    '-c', 'hg38.chrom.sizes',\n",
    "    '-p', 'peaks_no_blacklist.bed',\n",
    "    '-n', 'output_negatives.bed',\n",
    "    '-fl', 'splits/fold_0.json',\n",
    "    '-b', 'bias_model/models/k562_bias.h5',\n",
    "    '-o', 'chrombpnet_model/'\n",
    "]\n",
    "args = main()\n",
    "#and now we can simulate our args\n",
    "\n",
    "#now we modify args\n",
    "import json\n",
    "import os\n",
    "if args.file_prefix:\n",
    "    fpx = args.file_prefix+\"_\"\n",
    "else:\n",
    "    fpx = \"\"\n",
    "    \n",
    "# Shift bam and convert to bigwig\n",
    "# import chrombpnet.helpers.preprocessing.reads_to_bigwig as reads_to_bigwig\t\n",
    "args.output_prefix = os.path.join(args.output_dir,\"auxiliary/{}data\".format(fpx))\n",
    "args.plus_shift = None\n",
    "args.minus_shift = None\n",
    "args.bigwig = os.path.join(args.output_dir,\"auxiliary/{}data_unstranded.bw\".format(fpx))\n",
    "args.output_prefix = os.path.join(args.output_dir,\"evaluation/{}bw_shift_qc\".format(fpx))\n",
    "os.chdir('/data/leslie/sarthak/data/chrombpnet_test/')\n",
    "folds = json.load(open(args.chr_fold_path))\n",
    "assert(len(folds[\"valid\"]) > 0) # validation list of chromosomes is empty\n",
    "args.chr = folds[\"valid\"][0]\n",
    "args.pwm_width=24\n",
    "folds\n",
    "import copy\n",
    "import chrombpnet.training.models.chrombpnet_with_bias_model as chrombpnet_with_bias_model\n",
    "import chrombpnet.training.train as train\n",
    "args_copy = copy.deepcopy(args)\n",
    "if args_copy.architecture_from_file is None:\n",
    "    args_copy.architecture_from_file = \tchrombpnet_with_bias_model.__file__\n",
    "args_copy.peaks = os.path.join(args.output_dir,\"auxiliary/{}filtered.peaks.bed\".format(fpx))\n",
    "args_copy.nonpeaks = os.path.join(args.output_dir,\"auxiliary/{}filtered.nonpeaks.bed\".format(fpx))\n",
    "args_copy.output_prefix = os.path.join(args.output_dir,\"models/{}chrombpnet\".format(fpx))\n",
    "args_copy.params = os.path.join(args.output_dir,\"logs/{}chrombpnet_model_params.tsv\".format(fpx))\n",
    "args_copy #this is the official one that has all of the things specified!\n",
    "args = args_copy\n",
    "#but instead of directly calling train.main, we'll go through it to get to the source of our things!\n",
    "import numpy as np\n",
    "import chrombpnet.training.data_generators.initializers as initializers\n",
    "parameters = train.get_model_param_dict(args)\n",
    "print(parameters)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# get model architecture to load\n",
    "# model, architecture_module=train.get_model(args, parameters)\n",
    "\n",
    "# initialize generators to load data\n",
    "# train_generator = initializers.initialize_generators(args, \"train\", parameters, return_coords=False) #gets the peaks and takes forever to get the sequences\n",
    "# valid_generator = initializers.initialize_generators(args, \"valid\", parameters, return_coords=False)\n",
    "model, architecture_module=train.get_model(args, parameters) #this is killing it for some reason if we use the lt nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 2114, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " model_wo_bias (Functional)     [(None, 1000),       6377986     ['sequence[0][0]']               \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 1000),       217730      ['sequence[0][0]']               \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['model_wo_bias[0][1]',          \n",
      "                                                                  'model[0][1]']                  \n",
      "                                                                                                  \n",
      " logits_profile_predictions (Ad  (None, 1000)        0           ['model_wo_bias[0][0]',          \n",
      " d)                                                               'model[0][0]']                  \n",
      "                                                                                                  \n",
      " logcount_predictions (Lambda)  (None, 1)            0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,595,716\n",
      "Trainable params: 6,377,986\n",
      "Non-trainable params: 217,730\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2114, 4)\n"
     ]
    }
   ],
   "source": [
    "#let's have it be the same input\n",
    "import numpy as np\n",
    "data = np.array(range(2114)).reshape(1, 1, 2114)\n",
    "data = np.repeat(data, 64, axis=0)\n",
    "data = np.repeat(data, 4, axis=1)\n",
    "data = data.astype(np.float32)\n",
    "#and reshape it to be 64 x 2114 x 4\n",
    "data = np.transpose(data, (0,2,1))\n",
    "print(data.shape)\n",
    "#now put it through the model\n",
    "out = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000)\n",
      "(64, 1)\n",
      "[array([[-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ],\n",
      "       [-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ],\n",
      "       [-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ],\n",
      "       ...,\n",
      "       [-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ],\n",
      "       [-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ],\n",
      "       [-2236.4678, -2240.0198, -2243.559 , ..., -5759.782 , -5763.3086,\n",
      "        -5766.836 ]], dtype=float32), array([[4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807],\n",
      "       [4647.6807]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(out[0].shape)\n",
    "print(out[1].shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000)\n",
      "(64, 1)\n",
      "[<tf.Tensor: shape=(64, 1000), dtype=float32, numpy=\n",
      "array([[-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ],\n",
      "       [-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ],\n",
      "       [-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ],\n",
      "       ...,\n",
      "       [-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ],\n",
      "       [-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ],\n",
      "       [-2236.4683, -2240.02  , -2243.56  , ..., -5759.7803, -5763.312 ,\n",
      "        -5766.833 ]], dtype=float32)>, <tf.Tensor: shape=(64, 1), dtype=float32, numpy=\n",
      "array([[4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68],\n",
      "       [4647.68]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "out = model(data)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 2114, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " bpnet_1st_conv (Conv1D)        (None, 2094, 128)    10880       ['sequence[0][0]']               \n",
      "                                                                                                  \n",
      " bpnet_1conv (Conv1D)           (None, 2090, 128)    49280       ['bpnet_1st_conv[0][0]']         \n",
      "                                                                                                  \n",
      " bpnet_1crop (Cropping1D)       (None, 2090, 128)    0           ['bpnet_1st_conv[0][0]']         \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2090, 128)    0           ['bpnet_1conv[0][0]',            \n",
      "                                                                  'bpnet_1crop[0][0]']            \n",
      "                                                                                                  \n",
      " bpnet_2conv (Conv1D)           (None, 2082, 128)    49280       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " bpnet_2crop (Cropping1D)       (None, 2082, 128)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2082, 128)    0           ['bpnet_2conv[0][0]',            \n",
      "                                                                  'bpnet_2crop[0][0]']            \n",
      "                                                                                                  \n",
      " bpnet_3conv (Conv1D)           (None, 2066, 128)    49280       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " bpnet_3crop (Cropping1D)       (None, 2066, 128)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2066, 128)    0           ['bpnet_3conv[0][0]',            \n",
      "                                                                  'bpnet_3crop[0][0]']            \n",
      "                                                                                                  \n",
      " bpnet_4conv (Conv1D)           (None, 2034, 128)    49280       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " bpnet_4crop (Cropping1D)       (None, 2034, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 2034, 128)    0           ['bpnet_4conv[0][0]',            \n",
      "                                                                  'bpnet_4crop[0][0]']            \n",
      "                                                                                                  \n",
      " prof_out_precrop (Conv1D)      (None, 1960, 1)      9601        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " logits_profile_predictions_pre  (None, 1000, 1)     0           ['prof_out_precrop[0][0]']       \n",
      " flatten (Cropping1D)                                                                             \n",
      "                                                                                                  \n",
      " gap (GlobalAveragePooling1D)   (None, 128)          0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " logits_profile_predictions (Fl  (None, 1000)        0           ['logits_profile_predictions_pref\n",
      " atten)                                                          latten[0][0]']                   \n",
      "                                                                                                  \n",
      " logcount_predictions (Dense)   (None, 1)            129         ['gap[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 217,730\n",
      "Trainable params: 0\n",
      "Non-trainable params: 217,730\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#wait we expect them to give different outputs we're comparing the output of the bias model to the full chrombpnet model!! Let's redo it but this time only load the bias model!!\n",
    "\n",
    "submodel_layer = model.get_layer('model')\n",
    "submodel_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000)\n",
      "(64, 1)\n",
      "[array([[ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ],\n",
      "       [ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ],\n",
      "       [ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ],\n",
      "       ...,\n",
      "       [ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ],\n",
      "       [ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ],\n",
      "       [ -965.99817,  -967.7634 ,  -969.5292 , ..., -2726.4028 ,\n",
      "        -2728.168  , -2729.9333 ]], dtype=float32), array([[3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818],\n",
      "       [3082.5818]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "out = submodel_layer.predict(data)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
