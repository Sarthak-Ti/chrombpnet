Sender: LSF System <lsfadmin@lf01>
Subject: Job 7086846: <#!/bin/bash; # Source the bashrc file;source ~/.bashrc; # LSF directives;#BSUB -q gpuqueue;#BSUB -n 1;#BSUB -gpu "num=1";#BSUB -R "rusage[mem=32]";#BSUB -sla llSC2;#BSUB -W 5:00;#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out;#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err; # Activate your environment;source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command; mamba activate /data/leslie/sarthak/environments/chrombpnet; cd /data/leslie/sarthak/data/chrombpnet_test/; python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias pipeline \;        -ibam merged.bam \;        -d "ATAC" \;        -g hg38.fa \;        -c hg38.chrom.sizes \;        -p peaks_no_blacklist.bed \;        -n output_negatives.bed \;        -fl splits/fold_0.json \;        -b 0.5 \;        -o bias_model_1000/ \;        -fp k562 \;        -il 1024 \;        -ol 800 \;        --skip_preprocessing;        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/';        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias> in cluster <lila> Exited

Job <#!/bin/bash; # Source the bashrc file;source ~/.bashrc; # LSF directives;#BSUB -q gpuqueue;#BSUB -n 1;#BSUB -gpu "num=1";#BSUB -R "rusage[mem=32]";#BSUB -sla llSC2;#BSUB -W 5:00;#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out;#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err; # Activate your environment;source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command; mamba activate /data/leslie/sarthak/environments/chrombpnet; cd /data/leslie/sarthak/data/chrombpnet_test/; python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias pipeline \;        -ibam merged.bam \;        -d "ATAC" \;        -g hg38.fa \;        -c hg38.chrom.sizes \;        -p peaks_no_blacklist.bed \;        -n output_negatives.bed \;        -fl splits/fold_0.json \;        -b 0.5 \;        -o bias_model_1000/ \;        -fp k562 \;        -il 1024 \;        -ol 800 \;        --skip_preprocessing;        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/';        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias> was submitted from host <lf01> by user <tiwaris2> in cluster <lila> at Wed Jun 12 16:14:05 2024
Job was executed on host(s) <lf01>, in queue <gpuqueue>, as user <tiwaris2> in cluster <lila> at Wed Jun 12 16:14:07 2024
</home/tiwaris2> was used as the home directory.
</data/leslie/sarthak/data/chrombpnet_test> was used as the working directory.
Started at Wed Jun 12 16:14:07 2024
Terminated at Wed Jun 12 16:14:18 2024
Results reported at Wed Jun 12 16:14:18 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

# Source the bashrc file
source ~/.bashrc

# LSF directives
#BSUB -q gpuqueue
#BSUB -n 1
#BSUB -gpu "num=1"
#BSUB -R "rusage[mem=32]"
#BSUB -sla llSC2
#BSUB -W 5:00
#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out
#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err

# Activate your environment
source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command

mamba activate /data/leslie/sarthak/environments/chrombpnet

cd /data/leslie/sarthak/data/chrombpnet_test/

python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias pipeline \
        -ibam merged.bam \
        -d "ATAC" \
        -g hg38.fa \
        -c hg38.chrom.sizes \
        -p peaks_no_blacklist.bed \
        -n output_negatives.bed \
        -fl splits/fold_0.json \
        -b 0.5 \
        -o bias_model_1000/ \
        -fp k562 \
        -il 1024 \
        -ol 800 \
        --skip_preprocessing
        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/'
        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.35 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                8
    Run time :                                   11 sec.
    Turnaround time :                            13 sec.

The output (if any) follows:



PS:

Read file </data/leslie/sarthak/chrombpnet/jobs/7086846.err> for stderr output of this job.

