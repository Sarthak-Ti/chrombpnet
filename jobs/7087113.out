Sender: LSF System <lsfadmin@lt15>
Subject: Job 7087113: <#!/bin/bash; # Source the bashrc file;source ~/.bashrc; # LSF directives;#BSUB -q gpuqueue;#BSUB -n 1;#BSUB -gpu "num=1";#BSUB -R "rusage[mem=32]";#BSUB -sla llSC2;#BSUB -W 5:00;#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out;#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err; # Activate your environment;source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command; mamba activate /data/leslie/sarthak/environments/chrombpnet; cd /data/leslie/sarthak/data/chrombpnet_test/; #this command is done since the prediction failed but the model was trained, so it's easy to check and fix it; python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias qc \;        -bw bias_model_1000/auxiliary/k562_data_unstranded.bw \;        -bm bias_model_1000/models/k562_bias.h5 \;        -d "ATAC" \;        -g hg38.fa \;        -c hg38.chrom.sizes \;        -p peaks_no_blacklist.bed \;        -n output_negatives.bed \;        -fl splits/fold_0.json \;        -o bias_model_1000_qc/ \;        -fp k562 \;        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/';        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias> in cluster <lila> Exited

Job <#!/bin/bash; # Source the bashrc file;source ~/.bashrc; # LSF directives;#BSUB -q gpuqueue;#BSUB -n 1;#BSUB -gpu "num=1";#BSUB -R "rusage[mem=32]";#BSUB -sla llSC2;#BSUB -W 5:00;#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out;#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err; # Activate your environment;source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command; mamba activate /data/leslie/sarthak/environments/chrombpnet; cd /data/leslie/sarthak/data/chrombpnet_test/; #this command is done since the prediction failed but the model was trained, so it's easy to check and fix it; python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias qc \;        -bw bias_model_1000/auxiliary/k562_data_unstranded.bw \;        -bm bias_model_1000/models/k562_bias.h5 \;        -d "ATAC" \;        -g hg38.fa \;        -c hg38.chrom.sizes \;        -p peaks_no_blacklist.bed \;        -n output_negatives.bed \;        -fl splits/fold_0.json \;        -o bias_model_1000_qc/ \;        -fp k562 \;        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/';        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias> was submitted from host <lf01> by user <tiwaris2> in cluster <lila> at Wed Jun 12 17:22:25 2024
Job was executed on host(s) <lt15>, in queue <gpuqueue>, as user <tiwaris2> in cluster <lila> at Wed Jun 12 17:22:27 2024
</home/tiwaris2> was used as the home directory.
</data/leslie/sarthak/data/chrombpnet_test> was used as the working directory.
Started at Wed Jun 12 17:22:27 2024
Terminated at Wed Jun 12 17:24:22 2024
Results reported at Wed Jun 12 17:24:22 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

# Source the bashrc file
source ~/.bashrc

# LSF directives
#BSUB -q gpuqueue
#BSUB -n 1
#BSUB -gpu "num=1"
#BSUB -R "rusage[mem=32]"
#BSUB -sla llSC2
#BSUB -W 5:00
#BSUB -o /data/leslie/sarthak/chrombpnet/jobs/%J.out
#BSUB -e /data/leslie/sarthak/chrombpnet/jobs/%J.err

# Activate your environment
source ~/mambaforge/etc/profile.d/mamba.sh  # Adjust this line to your environment activation command

mamba activate /data/leslie/sarthak/environments/chrombpnet

cd /data/leslie/sarthak/data/chrombpnet_test/

#this command is done since the prediction failed but the model was trained, so it's easy to check and fix it

python /data/leslie/sarthak/chrombpnet/chrombpnet/CHROMBPNET.py bias qc \
        -bw bias_model_1000/auxiliary/k562_data_unstranded.bw \
        -bm bias_model_1000/models/k562_bias.h5 \
        -d "ATAC" \
        -g hg38.fa \
        -c hg38.chrom.sizes \
        -p peaks_no_blacklist.bed \
        -n output_negatives.bed \
        -fl splits/fold_0.json \
        -o bias_model_1000_qc/ \
        -fp k562 \
        # --save_data '/data/leslie/sarthak/data/chrombpnet_test/bias_data/'
        #this is done if we want to skip the preprocessing and where to save the data, but saving data is when we train the full model not bias

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   17.00 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.17 GB
    Total Requested Memory :                     32.00 GB
    Delta Memory :                               31.00 GB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                24
    Run time :                                   115 sec.
    Turnaround time :                            117 sec.

The output (if any) follows:

<argparse._ArgumentGroup object at 0x2b14ff3f73a0>
Namespace(cmd='bias', cmd_bias='qc', bigwig='bias_model_1000/auxiliary/k562_data_unstranded.bw', bias_model='bias_model_1000/models/k562_bias.h5', genome='hg38.fa', chrom_sizes='hg38.chrom.sizes', output_dir='bias_model_1000_qc/', data_type='ATAC', peaks='peaks_no_blacklist.bed', nonpeaks='output_negatives.bed', chr_fold_path='splits/fold_0.json', file_prefix='k562', batch_size=64, html_prefix='./')
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 sequence (InputLayer)          [(None, 1024, 4)]    0           []                               
                                                                                                  
 bpnet_1st_conv (Conv1D)        (None, 1004, 128)    10880       ['sequence[0][0]']               
                                                                                                  
 bpnet_1conv (Conv1D)           (None, 1000, 128)    49280       ['bpnet_1st_conv[0][0]']         
                                                                                                  
 bpnet_1crop (Cropping1D)       (None, 1000, 128)    0           ['bpnet_1st_conv[0][0]']         
                                                                                                  
 add (Add)                      (None, 1000, 128)    0           ['bpnet_1conv[0][0]',            
                                                                  'bpnet_1crop[0][0]']            
                                                                                                  
 bpnet_2conv (Conv1D)           (None, 992, 128)     49280       ['add[0][0]']                    
                                                                                                  
 bpnet_2crop (Cropping1D)       (None, 992, 128)     0           ['add[0][0]']                    
                                                                                                  
 add_1 (Add)                    (None, 992, 128)     0           ['bpnet_2conv[0][0]',            
                                                                  'bpnet_2crop[0][0]']            
                                                                                                  
 bpnet_3conv (Conv1D)           (None, 976, 128)     49280       ['add_1[0][0]']                  
                                                                                                  
 bpnet_3crop (Cropping1D)       (None, 976, 128)     0           ['add_1[0][0]']                  
                                                                                                  
 add_2 (Add)                    (None, 976, 128)     0           ['bpnet_3conv[0][0]',            
                                                                  'bpnet_3crop[0][0]']            
                                                                                                  
 bpnet_4conv (Conv1D)           (None, 944, 128)     49280       ['add_2[0][0]']                  
                                                                                                  
 bpnet_4crop (Cropping1D)       (None, 944, 128)     0           ['add_2[0][0]']                  
                                                                                                  
 add_3 (Add)                    (None, 944, 128)     0           ['bpnet_4conv[0][0]',            
                                                                  'bpnet_4crop[0][0]']            
                                                                                                  
 prof_out_precrop (Conv1D)      (None, 870, 1)       9601        ['add_3[0][0]']                  
                                                                                                  
 logits_profile_predictions_pre  (None, 800, 1)      0           ['prof_out_precrop[0][0]']       
 flatten (Cropping1D)                                                                             
                                                                                                  
 gap (GlobalAveragePooling1D)   (None, 128)          0           ['add_3[0][0]']                  
                                                                                                  
 logits_profile_predictions (Fl  (None, 800)         0           ['logits_profile_predictions_pref
 atten)                                                          latten[0][0]']                   
                                                                                                  
 logcount_predictions (Dense)   (None, 1)            129         ['gap[0][0]']                    
                                                                                                  
==================================================================================================
Total params: 217,730
Trainable params: 217,730
Non-trainable params: 0
__________________________________________________________________________________________________
got the model
loading peaks...


PS:

Read file </data/leslie/sarthak/chrombpnet/jobs/7087113.err> for stderr output of this job.

